package graph

// This file will be automatically regenerated based on the schema, any resolver implementations
// will be copied through when generating and any unknown code will be moved to the end.
// Code generated by github.com/99designs/gqlgen version v0.17.78

import (
	"context"
	"fmt"
	"strconv"
)

// InstancePrice is the resolver for the instancePrice field.
func (r *aWSComputeResolver) InstancePrice(ctx context.Context, obj *AWSCompute, typeArg string) (float64, error) {
	panic(fmt.Errorf("not implemented: InstancePrice - instancePrice"))
}

// Instances is the resolver for the instances field.
func (r *aWSComputeResolver) Instances(ctx context.Context, obj *AWSCompute) ([]*AWSInstance, error) {
	panic(fmt.Errorf("not implemented: Instances - instances"))
}

// PricePerGb is the resolver for the pricePerGB field.
func (r *aWSDataTransferResolver) PricePerGb(ctx context.Context, obj *AWSDataTransfer, direction string) (float64, error) {
	panic(fmt.Errorf("not implemented: PricePerGb - pricePerGB"))
}

// Inbound is the resolver for the inbound field.
func (r *aWSDataTransferResolver) Inbound(ctx context.Context, obj *AWSDataTransfer) (float64, error) {
	panic(fmt.Errorf("not implemented: Inbound - inbound"))
}

// Outbound is the resolver for the outbound field.
func (r *aWSDataTransferResolver) Outbound(ctx context.Context, obj *AWSDataTransfer) (float64, error) {
	panic(fmt.Errorf("not implemented: Outbound - outbound"))
}

// Compute is the resolver for the compute field.
func (r *aWSProviderResolver) Compute(ctx context.Context, obj *AWSProvider, region string) (*AWSCompute, error) {
	panic(fmt.Errorf("not implemented: Compute - compute"))
}

// Storage is the resolver for the storage field.
func (r *aWSProviderResolver) Storage(ctx context.Context, obj *AWSProvider, region string) (*AWSStorage, error) {
	panic(fmt.Errorf("not implemented: Storage - storage"))
}

// DataTransfer is the resolver for the dataTransfer field.
func (r *aWSProviderResolver) DataTransfer(ctx context.Context, obj *AWSProvider, region string) (*AWSDataTransfer, error) {
	panic(fmt.Errorf("not implemented: DataTransfer - dataTransfer"))
}

// PricePerGb is the resolver for the pricePerGB field.
func (r *aWSStorageResolver) PricePerGb(ctx context.Context, obj *AWSStorage, tier string) (float64, error) {
	panic(fmt.Errorf("not implemented: PricePerGb - pricePerGB"))
}

// Tiers is the resolver for the tiers field.
func (r *aWSStorageResolver) Tiers(ctx context.Context, obj *AWSStorage) ([]*AWSStorageTier, error) {
	panic(fmt.Errorf("not implemented: Tiers - tiers"))
}

// VMPrice is the resolver for the vmPrice field.
func (r *azureComputeResolver) VMPrice(ctx context.Context, obj *AzureCompute, size string) (float64, error) {
	panic(fmt.Errorf("not implemented: VMPrice - vmPrice"))
}

// Vms is the resolver for the vms field.
func (r *azureComputeResolver) Vms(ctx context.Context, obj *AzureCompute) ([]*AzureVM, error) {
	panic(fmt.Errorf("not implemented: Vms - vms"))
}

// PricePerGb is the resolver for the pricePerGB field.
func (r *azureDataTransferResolver) PricePerGb(ctx context.Context, obj *AzureDataTransfer, direction string) (float64, error) {
	panic(fmt.Errorf("not implemented: PricePerGb - pricePerGB"))
}

// Inbound is the resolver for the inbound field.
func (r *azureDataTransferResolver) Inbound(ctx context.Context, obj *AzureDataTransfer) (float64, error) {
	panic(fmt.Errorf("not implemented: Inbound - inbound"))
}

// Outbound is the resolver for the outbound field.
func (r *azureDataTransferResolver) Outbound(ctx context.Context, obj *AzureDataTransfer) (float64, error) {
	panic(fmt.Errorf("not implemented: Outbound - outbound"))
}

// Compute is the resolver for the compute field.
func (r *azureProviderResolver) Compute(ctx context.Context, obj *AzureProvider, region string) (*AzureCompute, error) {
	panic(fmt.Errorf("not implemented: Compute - compute"))
}

// Storage is the resolver for the storage field.
func (r *azureProviderResolver) Storage(ctx context.Context, obj *AzureProvider, region string) (*AzureStorage, error) {
	panic(fmt.Errorf("not implemented: Storage - storage"))
}

// DataTransfer is the resolver for the dataTransfer field.
func (r *azureProviderResolver) DataTransfer(ctx context.Context, obj *AzureProvider, region string) (*AzureDataTransfer, error) {
	panic(fmt.Errorf("not implemented: DataTransfer - dataTransfer"))
}

// PricePerGb is the resolver for the pricePerGB field.
func (r *azureStorageResolver) PricePerGb(ctx context.Context, obj *AzureStorage, tier string) (float64, error) {
	panic(fmt.Errorf("not implemented: PricePerGb - pricePerGB"))
}

// Tiers is the resolver for the tiers field.
func (r *azureStorageResolver) Tiers(ctx context.Context, obj *AzureStorage) ([]*AzureStorageTier, error) {
	panic(fmt.Errorf("not implemented: Tiers - tiers"))
}

// CreateMessage creates a new message
func (r *mutationResolver) CreateMessage(ctx context.Context, content string) (*Message, error) {
	msg, err := r.DB.CreateMessage(content)
	if err != nil {
		return nil, fmt.Errorf("failed to create message: %w", err)
	}

	return &Message{
		ID:        strconv.Itoa(msg.ID),
		Content:   msg.Content,
		CreatedAt: msg.CreatedAt.Format("2006-01-02T15:04:05Z"),
	}, nil
}

// StartNormalization starts a new normalization job
func (r *mutationResolver) StartNormalization(ctx context.Context, config NormalizationConfigInput) (*ETLJob, error) {
	if r.pipeline == nil {
		return nil, fmt.Errorf("ETL pipeline not initialized")
	}

	// Convert GraphQL input to ETL configuration
	etlConfig := etl.JobConfiguration{
		BatchSize:         1000, // default
		ConcurrentWorkers: 4,    // default
	}

	// Set optional fields
	if config.BatchSize != nil {
		etlConfig.BatchSize = *config.BatchSize
	}
	if config.ConcurrentWorkers != nil {
		etlConfig.ConcurrentWorkers = *config.ConcurrentWorkers
	}
	if config.ClearExisting != nil {
		etlConfig.ClearExisting = *config.ClearExisting
	}
	if config.DryRun != nil {
		etlConfig.DryRun = *config.DryRun
	}
	if len(config.Providers) > 0 {
		etlConfig.Providers = config.Providers
	}
	if len(config.Regions) > 0 {
		etlConfig.Regions = config.Regions
	}
	if len(config.Services) > 0 {
		etlConfig.Services = config.Services
	}

	// Convert job type
	jobType := convertGraphQLJobType(config.Type)

	// Start the job
	job, err := r.pipeline.StartJob(jobType, etlConfig)
	if err != nil {
		return nil, fmt.Errorf("failed to start normalization job: %w", err)
	}

	return convertJobToGraphQL(job), nil
}

// CancelETLJob cancels a running ETL job
func (r *mutationResolver) CancelETLJob(ctx context.Context, id string) (bool, error) {
	if r.pipeline == nil {
		return false, fmt.Errorf("ETL pipeline not initialized")
	}

	err := r.pipeline.CancelJob(id)
	if err != nil {
		return false, fmt.Errorf("failed to cancel job: %w", err)
	}

	return true, nil
}

// Hello is a simple hello world query
func (r *queryResolver) Hello(ctx context.Context) (string, error) {
	return "Hello from Cloud Price Compare GraphQL API!", nil
}

// Messages retrieves all messages
func (r *queryResolver) Messages(ctx context.Context) ([]*Message, error) {
	dbMessages, err := r.DB.GetMessages()
	if err != nil {
		return nil, fmt.Errorf("failed to get messages: %w", err)
	}

	messages := make([]*Message, len(dbMessages))
	for i, msg := range dbMessages {
		messages[i] = &Message{
			ID:        strconv.Itoa(msg.ID),
			Content:   msg.Content,
			CreatedAt: msg.CreatedAt.Format("2006-01-02T15:04:05Z"),
		}
	}

	return messages, nil
}

// Providers retrieves all providers
func (r *queryResolver) Providers(ctx context.Context) ([]*Provider, error) {
	dbProviders, err := r.DB.GetProviders()
	if err != nil {
		return nil, fmt.Errorf("failed to get providers: %w", err)
	}

	providers := make([]*Provider, len(dbProviders))
	for i, p := range dbProviders {
		providers[i] = &Provider{
			ID:        strconv.Itoa(p.ID),
			Name:      p.Name,
			CreatedAt: p.CreatedAt.Format("2006-01-02T15:04:05Z"),
		}
	}

	return providers, nil
}

// Categories retrieves all categories
func (r *queryResolver) Categories(ctx context.Context) ([]*Category, error) {
	dbCategories, err := r.DB.GetCategories()
	if err != nil {
		return nil, fmt.Errorf("failed to get categories: %w", err)
	}

	categories := make([]*Category, len(dbCategories))
	for i, c := range dbCategories {
		categories[i] = &Category{
			ID:          strconv.Itoa(c.ID),
			Name:        c.Name,
			Description: c.Description,
			CreatedAt:   c.CreatedAt.Format("2006-01-02T15:04:05Z"),
		}
	}

	return categories, nil
}

// AWS is the resolver for the aws field.
func (r *queryResolver) AWS(ctx context.Context) (*AWSProvider, error) {
	panic(fmt.Errorf("not implemented: AWS - aws"))
}

// Azure returns the Azure provider resolver
func (r *queryResolver) Azure(ctx context.Context) (*AzureProvider, error) {
	return &AzureProvider{resolver: r.Resolver}, nil
}

// EtlJob retrieves a specific ETL job by ID
func (r *queryResolver) EtlJob(ctx context.Context, id string) (*ETLJob, error) {
	if r.pipeline == nil {
		return nil, fmt.Errorf("ETL pipeline not initialized")
	}

	job, exists := r.pipeline.GetJob(id)
	if !exists {
		return nil, nil // GraphQL handles null return for not found
	}

	return convertJobToGraphQL(job), nil
}

// EtlJobs retrieves all ETL jobs
func (r *queryResolver) EtlJobs(ctx context.Context) ([]*ETLJob, error) {
	if r.pipeline == nil {
		return nil, fmt.Errorf("ETL pipeline not initialized")
	}

	jobs := r.pipeline.GetAllJobs()
	result := make([]*ETLJob, len(jobs))

	for i, job := range jobs {
		result[i] = convertJobToGraphQL(job)
	}

	return result, nil
}

// OptimizeRegions is the resolver for the optimizeRegions field.
func (r *queryResolver) OptimizeRegions(ctx context.Context, workload WorkloadInput) ([]*RegionOptimization, error) {
	panic(fmt.Errorf("not implemented: OptimizeRegions - optimizeRegions"))
}

// CompareRegions is the resolver for the compareRegions field.
func (r *queryResolver) CompareRegions(ctx context.Context, workload WorkloadInput, regions []*RegionInput) ([]*RegionComparison, error) {
	panic(fmt.Errorf("not implemented: CompareRegions - compareRegions"))
}

// AWSCompute returns AWSComputeResolver implementation.
func (r *Resolver) AWSCompute() AWSComputeResolver { return &aWSComputeResolver{r} }

// AWSDataTransfer returns AWSDataTransferResolver implementation.
func (r *Resolver) AWSDataTransfer() AWSDataTransferResolver { return &aWSDataTransferResolver{r} }

// AWSProvider returns AWSProviderResolver implementation.
func (r *Resolver) AWSProvider() AWSProviderResolver { return &aWSProviderResolver{r} }

// AWSStorage returns AWSStorageResolver implementation.
func (r *Resolver) AWSStorage() AWSStorageResolver { return &aWSStorageResolver{r} }

// AzureCompute returns AzureComputeResolver implementation.
func (r *Resolver) AzureCompute() AzureComputeResolver { return &azureComputeResolver{r} }

// AzureDataTransfer returns AzureDataTransferResolver implementation.
func (r *Resolver) AzureDataTransfer() AzureDataTransferResolver {
	return &azureDataTransferResolver{r}
}

// AzureProvider returns AzureProviderResolver implementation.
func (r *Resolver) AzureProvider() AzureProviderResolver { return &azureProviderResolver{r} }

// AzureStorage returns AzureStorageResolver implementation.
func (r *Resolver) AzureStorage() AzureStorageResolver { return &azureStorageResolver{r} }

// Mutation returns MutationResolver implementation.
func (r *Resolver) Mutation() MutationResolver { return &mutationResolver{r} }

// Query returns QueryResolver implementation.
func (r *Resolver) Query() QueryResolver { return &queryResolver{r} }

type aWSComputeResolver struct{ *Resolver }
type aWSDataTransferResolver struct{ *Resolver }
type aWSProviderResolver struct{ *Resolver }
type aWSStorageResolver struct{ *Resolver }
type azureComputeResolver struct{ *Resolver }
type azureDataTransferResolver struct{ *Resolver }
type azureProviderResolver struct{ *Resolver }
type azureStorageResolver struct{ *Resolver }
type mutationResolver struct{ *Resolver }
type queryResolver struct{ *Resolver }
